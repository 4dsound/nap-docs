<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAP: Audio</title>
<link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Nunito+Sans" rel="stylesheet">
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<script type="text/javascript">
  function inlineSVGfromIFrame () {
    console.log("blaaat")
    var alreadyImported = Boolean(document.querySelectorAll('.dyncontent svg').length)
    if (alreadyImported) return
    var allIFrames = document.querySelectorAll('.dyncontent iframe')
    var allContentBoxes = document.querySelectorAll('.dyncontent .center')
    allIFrames.forEach(function(iFrame, index) {
      var svgElem = iFrame.contentWindow.document.documentElement.cloneNode(true)
      allContentBoxes[index].appendChild(svgElem)
      iFrame.style.display = 'none'
    })
  }
  window.addEventListener("load", inlineSVGfromIFrame, false)
</script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../customdoxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><a href="www.nap.tech"><img alt="Logo" src="../../nap_tech_logo.svg"/></a></td>
  <td id="projectalign" style="padding-left: 0.5em;"><a href="http://www.napframework.com">
   <div id="projectname">NAP
   </div>
  </a>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Audio </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><ul>
<li><a class="el" href="../../dd/d1e/audio.html#audio_playback">Audio Playback</a><ul>
<li><a class="el" href="../../dd/d1e/audio.html#audio_files">Files</a></li>
<li><a class="el" href="../../dd/d1e/audio.html#audio_playback_comp">Playback</a></li>
<li><a class="el" href="../../dd/d1e/audio.html#audio_output_comp">Output</a></li>
</ul>
</li>
<li><a class="el" href="../../dd/d1e/audio.html#audio_input_comp">Audio Input</a><ul>
<li><a class="el" href="../../dd/d1e/audio.html#audio_analysis">Analysis</a></li>
</ul>
</li>
<li><a class="el" href="../../dd/d1e/audio.html#audio_custom">Writing Custom Audio Components</a><ul>
<li><a class="el" href="../../dd/d1e/audio.html#audio_nodes">Nodes</a></li>
<li><a class="el" href="../../dd/d1e/audio.html#audio_comps">Components</a></li>
<li><a class="el" href="../../dd/d1e/audio.html#audio_thread_safety">Thread Safety</a></li>
</ul>
</li>
</ul>
<p>NAP is equipped with a very flexible and modular audio engine that can be used to send or receive audio from a hardware audio interface, open and read audio files and to perform all kinds of DSP processing on audio signals. On top of this engine a few components are offered to guide you with some common audio tasks, such as playing back audio from a file, receiving audio input from an audio device and reading the output level from an audio signal. A more advanced audio module that is tailored to allow you to design and control custom DSP networks dynamically is currently in development.</p>
<h1><a class="anchor" id="audio_playback"></a>
Audio Playback </h1>
<p>A very common audio task is playing back samples from an audio file in order to equip your app with sound. For an example how to do this have a look at the demo "audioplayback" in the demos directory.</p>
<h2><a class="anchor" id="audio_files"></a>
Files </h2>
<p>First of all we need a resource that loads an audio file from disk and keeps it in memory. This is the <a class="el" href="../../d1/d65/classnap_1_1audio_1_1_audio_file_resource.html">AudioFileResource</a>. Note that all classes and functions in the audio engine are defined within the audio namespace.</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot;: &quot;nap::audio::AudioFileResource&quot;,</div><div class="line">    &quot;mID&quot;: &quot;audioFile&quot;,</div><div class="line">    &quot;AudioFilePath&quot;: &quot;hang.wav&quot;</div><div class="line">}</div></div><!-- fragment --><p> (Note: altough displayed here, please don’t edit JSON files by hand and use <a class="el" href="../../da/d34/napkin.html">Napkin</a>!)</p>
<p>It is pretty straightforward, the audio file named in AudioFilePath will be loaded into memory on initialization.</p>
<h2><a class="anchor" id="audio_playback_comp"></a>
Playback </h2>
<p>Secondly, we need an entity with a <a class="el" href="../../d3/d49/classnap_1_1audio_1_1_playback_component.html">PlaybackComponent</a>:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot;: &quot;nap::audio::PlaybackComponent&quot;,</div><div class="line">    &quot;mID&quot;: &quot;playbackComponent&quot;,</div><div class="line">    &quot;ChannelRouting&quot;: [ 0, 1 ],</div><div class="line">    &quot;Buffer&quot;: &quot;audioFile&quot;,</div><div class="line">    &quot;AutoPlay&quot;: false,</div><div class="line">    &quot;StartPosition&quot;: 0,</div><div class="line">    &quot;Duration&quot;: 0,</div><div class="line">    &quot;FadeInTime&quot;: 50,</div><div class="line">    &quot;FadeOutTime&quot;: 50,</div><div class="line">    &quot;Pitch&quot;: 1.0,</div><div class="line">    &quot;Gain&quot;: 1.0,</div><div class="line">    &quot;StereoPanning&quot;: 0.5</div><div class="line">}</div></div><!-- fragment --><p> (again, please don’t type this by hand and use <a class="el" href="../../da/d34/napkin.html">Napkin</a>)</p>
<p>The PlaybackComponent offers the functionality to play audio from a buffer resource. (like the <a class="el" href="../../d1/d65/classnap_1_1audio_1_1_audio_file_resource.html">AudioFileResource</a>) As you can see there are a number of parameters available to control the playback. The Buffer points to the resource containing the audio data to be played back. The AutoPlay parameter tells the component to start playback immediately after initialization. The other parameters are pretty self explanatory and can also be modulated on the instance of the component at runtime. Note that all parameters that contain a time value are expressed in milliseconds, because in audio-land we often have to deal with smaller timescales.</p>
<h2><a class="anchor" id="audio_output_comp"></a>
Output </h2>
<p>This PlaybackComponent on its own does not produce any sound coming out of the speakers. The reason for this is we do not only need to produce an audio signal, we also have to rout it to the audio device. This is done using an <a class="el" href="../../df/d82/classnap_1_1audio_1_1_output_component.html">OutputComponent</a>.</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot;: &quot;nap::audio::OutputComponent&quot;,</div><div class="line">    &quot;mID&quot;: &quot;output&quot;,</div><div class="line">    &quot;Routing&quot;: [ 0, 1 ],</div><div class="line">    &quot;Input&quot;: &quot;playbackComponent&quot;</div><div class="line">}</div></div><!-- fragment --><p> This component simply tells the audio engine to send the audio signals produced by the component specified as Input to the hardware outputs. The int array property Routing tells for each hardware output channel which channel of the input audio it will be routed to it. A value of -1 means no output will be sent to the corresponding channel.</p>
<p>If we add these three objects to an app and set the AutoPlay property to true we should hear a sound once we fire up the app. Furthermore we can control the <a class="el" href="../../d3/d49/classnap_1_1audio_1_1_playback_component.html">PlaybackComponent</a> from our app’s <a class="el" href="../../d4/dda/classnap_1_1_base_app.html#a86ea8e044f33b97f2c5ea32cdb67e1d3">update()</a> method to make the sound responsive to app logic, for example through a GUI button:</p>
<div class="fragment"><div class="line">ImGui::Begin(<span class="stringliteral">&quot;Audio Playback&quot;</span>);</div><div class="line"><span class="keywordflow">if</span> (!playbackComponent-&gt;isPlaying())</div><div class="line">{</div><div class="line">    <span class="keywordflow">if</span> (ImGui::Button(<span class="stringliteral">&quot;Play&quot;</span>))</div><div class="line">        playbackComponent-&gt;start(mStartPosition, mDuration);</div><div class="line">}</div><div class="line"><span class="keywordflow">else</span> {</div><div class="line">    <span class="keywordflow">if</span> (ImGui::Button(<span class="stringliteral">&quot;Stop&quot;</span>))</div><div class="line">        playbackComponent-&gt;stop();</div><div class="line">}</div></div><!-- fragment --><h1><a class="anchor" id="audio_input_comp"></a>
Audio Input </h1>
<p>In many cases we might need to use an audio signal directly from the hardware input of your audio device, such as a microphone input or line in signal. For this case we use <a class="el" href="../../db/d0a/classnap_1_1audio_1_1_audio_input_component.html">InputComponent</a>:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot;: &quot;nap::audio::AudioInputComponent&quot;,</div><div class="line">    &quot;mID&quot;: &quot;input&quot;,</div><div class="line">    &quot;Channels&quot;: [ 0 ]</div><div class="line">}</div></div><!-- fragment --><p>This component provides us with an audio signal containing the input from hardware channel 0 of our audio device. Note that in NAP (like everywhere else in C++, but possibly unlike most high level audio software) we start counting channel numbers from zero. This component can be used as an input source for the <a class="el" href="../../df/d82/classnap_1_1audio_1_1_output_component.html">OutputComponent</a> for example, pretty much like the <a class="el" href="../../d3/d49/classnap_1_1audio_1_1_playback_component.html">PlaybackComponent</a>. The reason for this is that they are both derived from <a class="el" href="../../d5/dcb/classnap_1_1audio_1_1_audio_component_base.html">AudioComponentBase</a>. More about this later in <a class="el" href="../../dd/d1e/audio.html#audio_custom">Writing a custom audio component</a>.</p>
<h2><a class="anchor" id="audio_analysis"></a>
Analysis </h2>
<p>In case you intend to use NAP to render visuals that respond to an audio signal you can use <a class="el" href="../../d7/db8/classnap_1_1audio_1_1_level_meter_component.html">LevelMeterComponent</a>. This component, pretty much like the <a class="el" href="../../df/d82/classnap_1_1audio_1_1_output_component.html">OutputComponent</a>, takes its input from a component derived from <a class="el" href="../../d5/dcb/classnap_1_1audio_1_1_audio_component_base.html">AudioComponentBase</a>. Instead of routing the signal to a hardware output though the component makes an analysis of the mean amplitude of the signal. It can be tuned to analyze a certain frequency band and also it's responsiveness can be finetuned. The output level can be requested at any given moment and used as a parameter to render visuals. For an example how this works, have a look at the "audioanalysis" demo:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot;: &quot;nap::audio::LevelMeterComponent&quot;,</div><div class="line">    &quot;mID&quot;: &quot;levelMeter&quot;,</div><div class="line">    &quot;Input&quot;: &quot;playbackComponent&quot;,</div><div class="line">    &quot;AnalysisWindowSize&quot;: 10.0,</div><div class="line">    &quot;MeterType&quot;: &quot;RMS&quot;,</div><div class="line">    &quot;FilterInput&quot;: true,</div><div class="line">    &quot;CenterFrequency&quot;: 400.0,</div><div class="line">    &quot;BandWidth&quot;: 100.0,</div><div class="line">    &quot;Channel&quot;: 0</div><div class="line">}</div></div><!-- fragment --><p> Be aware that the component always analyzes one single frequency band on one single input channel. If you need to analyze multiple channels or multiple different frequency bands, you can use multiple LevelMeterComponents together to achieve this.</p>
<h1><a class="anchor" id="audio_custom"></a>
Writing Custom Audio Components </h1>
<h2><a class="anchor" id="audio_nodes"></a>
Nodes </h2>
<p>Behind the audio components described in this chapter runs a very modular open system that is designed to implement all sorts of custom DSP systems for audio purposes. This is the backbone of the NAP audio module. The heart of this system is the <a class="el" href="../../db/d55/classnap_1_1audio_1_1_node_manager.html">Nodemanager</a>, that lives within the <a class="el" href="../../df/d42/classnap_1_1audio_1_1_audio_service.html">AudioService</a>. The NodeManager processes a collection of <a class="el" href="../../dc/d0d/classnap_1_1audio_1_1_node.html">Nodes</a> that are connected together to form a DSP network. The baseclass of all nodes is <a class="el" href="../../dc/d0d/classnap_1_1audio_1_1_node.html">Node</a>. Each node can have a number of <a class="el" href="../../d4/dd5/classnap_1_1audio_1_1_input_pin.html">input</a> and <a class="el" href="../../dc/d5a/classnap_1_1audio_1_1_output_pin.html">output</a> pins that can be used to connect nodes. The pins and their connections represent the flow of audio signals within the DSP system. Each <a class="el" href="../../dc/d0d/classnap_1_1audio_1_1_node.html">Node</a> has a process() method that defines how the node calculates it's output signals from it's input signals.</p>
<p>There are two special case nodes: the <a class="el" href="../../d3/d8d/classnap_1_1audio_1_1_input_node.html">InputNode</a> and the <a class="el" href="../../d2/da1/classnap_1_1audio_1_1_output_node.html">OutputNode</a>. The InputNode has one output pin that contains the audio signal from a hardware input channel on the audio device. The OutputNode has one input from which the audio signal will be routed to a hardware output channel.</p>
<h2><a class="anchor" id="audio_comps"></a>
Audio Components </h2>
<p>Users can design their custom audio components by deriving from <a class="el" href="../../d5/dcb/classnap_1_1audio_1_1_audio_component_base.html">AudioComponentBase</a> and <a class="el" href="../../da/dde/classnap_1_1audio_1_1_audio_component_base_instance.html">AudioComponentBaseInstance</a>. Custom audio components can be used as input for <a class="el" href="../../df/d82/classnap_1_1audio_1_1_output_component.html">OutputComponent</a> and <a class="el" href="../../d7/db8/classnap_1_1audio_1_1_level_meter_component.html">LevelMeterComponent</a>. An audio component instance always contains a number of nodes that are interconnected to form a DSP system. The methods <a class="el" href="../../d6/d4a/classnap_1_1audio_1_1_i_multi_channel_output.html#a791597c84869d654b5c37d964d33409c">getChannelCount</a> and <a class="el" href="../../d6/d4a/classnap_1_1audio_1_1_i_multi_channel_output.html#a5f2ba321482828d4ad515092735da103">getOutputForChannel</a> have to be overwritten to respectively return the number of audio signals the component outputs and an output pin from one of it's nodes for a given channel.</p>
<h2><a class="anchor" id="audio_thread_safety"></a>
Thread Safety </h2>
<p>Because Nodes are processed on a separate audio thread we need to declare them enclosed within a <a class="el" href="../../df/d53/classnap_1_1audio_1_1_safe_owner.html">SafeOwner</a> object. Pointers to the node have to be of the type <a class="el" href="../../da/d06/classnap_1_1audio_1_1_safe_ptr.html">SafePtr</a> and are aqcuired using SafeOwner's <a class="el" href="../../df/d53/classnap_1_1audio_1_1_safe_owner.html#ae6cac289409ced85f15cf221a3909a16">get</a> method. This all is to make sure that when the node is destroyed or goes out of scope it will not crash the audio thread that might currently be processing the node. The <a class="el" href="../../df/d42/classnap_1_1audio_1_1_audio_service.html">AudioService</a> takes care of this using a garbage collection system. </p>
</div></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.13-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
<a href="http://www.doxygen.org/index.html"> Generated by doxygen</a></small></address>
</body>
</html>
