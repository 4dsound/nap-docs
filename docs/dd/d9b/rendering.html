<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAP: Rendering</title>
<link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Nunito+Sans" rel="stylesheet">
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<script type="text/javascript">
  function inlineSVGfromIFrame () {
    console.log("blaaat")
    var alreadyImported = Boolean(document.querySelectorAll('.dyncontent svg').length)
    if (alreadyImported) return
    var allIFrames = document.querySelectorAll('.dyncontent iframe')
    var allContentBoxes = document.querySelectorAll('.dyncontent .center')
    allIFrames.forEach(function(iFrame, index) {
      var svgElem = iFrame.contentWindow.document.documentElement.cloneNode(true)
      allContentBoxes[index].appendChild(svgElem)
      iFrame.style.display = 'none'
    })
  }
  window.addEventListener("load", inlineSVGfromIFrame, false)
</script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../customdoxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><a href="https://nap.tech"><img alt="Logo" src="../../nap_tech_logo.svg"/></a></td>
  <td id="projectalign" style="padding-left: 0.5em;"><a href="http://www.napframework.com">
   <div id="projectname">NAP
   </div>
  </a>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Rendering </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><ul>
<li><a class="el" href="../../dd/d9b/rendering.html#render_intro">Introduction</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#key_features">Key Features</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#render_config">Configuration</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#render_example">Example</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#meshes">Meshes</a><ul>
<li><a class="el" href="../../dd/d9b/rendering.html#creating_meshes">Creating Meshes</a><ul>
<li><a class="el" href="../../dd/d9b/rendering.html#mesh_from_file">Mesh From File</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#predefined_shapes">Predefined Shapes</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#mesh_resource">Mesh Resource</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#custom_mesh">Custom Mesh C++</a></li>
</ul>
</li>
<li><a class="el" href="../../dd/d9b/rendering.html#mesh_format">Mesh Format</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#mesh_usage">Mesh Usage</a></li>
</ul>
</li>
<li><a class="el" href="../../dd/d9b/rendering.html#text">Text</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#materials">Materials and Shaders</a><ul>
<li><a class="el" href="../../dd/d9b/rendering.html#vertex_attrs">Vertex Attributes</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#default_attrs">Default Vertex Attributes</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#uniforms">Uniforms</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#samplers">Samplers</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#blending">Color Blending</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#depth">Depth</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#renderwithmaterials">Rendering Meshes</a></li>
</ul>
</li>
<li><a class="el" href="../../dd/d9b/rendering.html#textures">Textures</a><ul>
<li><a class="el" href="../../dd/d9b/rendering.html#creating_textures">Creating Textures</a><ul>
<li><a class="el" href="../../dd/d9b/rendering.html#gpu_textures">GPU Textures</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#images">Images</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#image_from_file">Image From File</a></li>
</ul>
</li>
<li><a class="el" href="../../dd/d9b/rendering.html#reading_textures">Reading Textures From The GPU</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#texture_sampling">Texture Sampling</a></li>
</ul>
</li>
<li><a class="el" href="../../dd/d9b/rendering.html#multi_screen">Windows</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#offscreen_rendering">Offscreen Rendering</a></li>
<li><a class="el" href="../../dd/d9b/rendering.html#cameras">Cameras</a></li>
</ul>
<h1><a class="anchor" id="render_intro"></a>
Introduction </h1>
<p>The NAP renderer is designed to be open and flexible. All render related functionality is exposed as a set of building blocks instead of a fixed function pipeline. You can use these blocks to set up your own rendering pipeline. Meshes, textures, materials, shaders, rendertargets, cameras and windows form the basis of these tools. They can be authored using JSON and are exported using your favourite content creation program (Photoshop, Maya etc.)</p>
<p>NAP uses <a href="https://www.khronos.org/vulkan/" target="_blank">Vulkan</a> to render objects but, contrary to popular game engines such as Unity or Unreal, doesn't lock down the rendering process. An object that can be rendered isn't rendered by default: you explicitly have to tell the renderer:</p>
<ul>
<li>That you want to render an object</li>
<li>How you want to render an object</li>
<li>Where to render it to, ie: it's destination</li>
</ul>
<p>The destination is always a render target and NAP currently offers two: directly to a <a class="el" href="../../d6/d4f/classnap_1_1_render_window.html">window</a> or an <a class="el" href="../../de/dd1/classnap_1_1_render_target.html">off-screen target</a>. Often you want to render a set of objects to a texture before rendering the textures to screen. Or you might want to render only a sub-set of objects to screen one and another set of objects to screen two. This is one of NAPs biggest strengths and offers a lot of flexibility in deciding how you want to draw things.</p>
<h1><a class="anchor" id="key_features"></a>
Key Features </h1>
<ul>
<li>Build your own render pipeline using easy to understand building blocks.</li>
<li>Meshes are not limited to a specific set of vertex attributes such as 'color', 'uv' etc. Any attribute, such as ‘wind’ or ‘heat’, can be added to drive procedural effects.</li>
<li>NAP supports both static and dynamic meshes. It's easy to bind your own attributes to materials using a safe and easy to understand binding system.</li>
<li>Rendering the same content to multiple windows is supported natively.</li>
<li>All render functionality is fully compatible with the real-time editing system. Textures, meshes or shaders can be modified and reloaded instantly without having to restart the application.</li>
</ul>
<h1><a class="anchor" id="render_config"></a>
Configuration </h1>
<p>All global render settings are configurable using using the <a class="el" href="../../df/d57/classnap_1_1_render_service_configuration.html">nap::RenderServiceConfiguration</a>. The render engine creates a Vulkan 1.0 instance by default, but applications may use Vulkan 1.1 and 1.2 functionality if required. Make sure to set the required major and minor vulkan version accordingly. The application will not start if the device does not support the selected (and therefore required) version of Vulkan.</p>
<h1><a class="anchor" id="render_example"></a>
Example </h1>
<p>To follow this example it's good to read the high level <a class="el" href="../../d1/d76/system.html">system</a> documentation first. This example renders a rotating sphere with a world texture to the first screen. This example is part of the 'HelloWorld' demo. To render a rotating sphere we need a:</p>
<ul>
<li><a class="el" href="../../d6/d4f/classnap_1_1_render_window.html">Window</a></li>
<li><a class="el" href="../../d6/d7b/classnap_1_1_sphere_mesh.html">Sphere</a></li>
<li><a class="el" href="../../dd/d44/classnap_1_1_shader.html">Shader</a></li>
<li><a class="el" href="../../d2/de3/classnap_1_1_material.html">Material</a></li>
<li><a class="el" href="../../dd/d82/classnap_1_1_image.html">Image</a></li>
<li><a class="el" href="../../d6/d3d/classnap_1_1_persp_camera_component.html">Camera Component</a></li>
<li><a class="el" href="../../d4/d61/classnap_1_1_renderable_mesh_component.html">Render Component</a></li>
<li><a class="el" href="../../de/d34/classnap_1_1_transform_component.html">Transform Component</a></li>
<li><a class="el" href="../../d1/de7/classnap_1_1_rotate_component.html">Rotate Component</a></li>
</ul>
<p>Some parts might look familiar, others are new. The most important new parts are the material, render and rotate component. The rotate component rotates the sphere along the y axis, the render component ties a renderable <a class="el" href="../../dd/dac/classnap_1_1_i_mesh.html">mesh</a> to a material. Every material points to a shader. The material is applied to the mesh before being rendered to (in this case) the screen. You will notice that the actual application will contain almost no code, most of the functionality is defined by the various objects and components. The only thing we have to do is tell the renderer to render the sphere using a particular camera.</p>
<p>But let's begin by defining some of the resources in JSON. Make sure to use <a class="el" href="../../da/d34/napkin.html">Napkin</a> (our JSON editor) to do this for you:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot;: &quot;nap::RenderWindow&quot;,</div><div class="line">    &quot;mID&quot;: &quot;Window0&quot;,</div><div class="line">    &quot;Borderless&quot;: false,</div><div class="line">    &quot;Resizable&quot;: true,</div><div class="line">    &quot;Visible&quot;: true,</div><div class="line">    &quot;Title&quot;: &quot;Window 1&quot;,</div><div class="line">    &quot;Width&quot;: 1280,</div><div class="line">    &quot;Height&quot;: 720,</div><div class="line">    &quot;Mode&quot;: &quot;Immediate&quot;,</div><div class="line">    &quot;Samples&quot;: &quot;Four&quot;</div><div class="line">},</div><div class="line">{</div><div class="line">    &quot;Type&quot;: &quot;nap::ImageFromFile&quot;,</div><div class="line">    &quot;mID&quot;: &quot;WorldTexture&quot;,</div><div class="line">    &quot;Usage&quot;: &quot;Static&quot;,</div><div class="line">    &quot;ImagePath&quot;: &quot;world_texture.png&quot;,</div><div class="line">    &quot;GenerateLods&quot;: true</div><div class="line">},</div><div class="line">{</div><div class="line">    &quot;Type&quot; : &quot;nap::ShaderFromFile&quot;,</div><div class="line">    &quot;mID&quot;: &quot;WorldShader&quot;,</div><div class="line">    &quot;VertShader&quot;: &quot;shaders/world.vert&quot;,</div><div class="line">    &quot;FragShader&quot;: &quot;shaders/world.frag&quot;</div><div class="line">},</div><div class="line">{</div><div class="line">    &quot;Type&quot;: &quot;nap::SphereMesh&quot;,</div><div class="line">    &quot;mID&quot;: &quot;WorldMesh&quot;,</div><div class="line">    &quot;Radius&quot;: 1.0,</div><div class="line">    &quot;Rings&quot;: 50.0,</div><div class="line">    &quot;Sectors&quot;: 50.0</div><div class="line">},</div></div><!-- fragment --><p>These resources are rather straight-forward. We tell NAP we want a <a class="el" href="../../d6/d4f/classnap_1_1_render_window.html">render window</a>, <a class="el" href="../../d3/d21/classnap_1_1_image_from_file.html">image</a>, <a class="el" href="../../dd/d44/classnap_1_1_shader.html">shader</a> and <a class="el" href="../../d6/d7b/classnap_1_1_sphere_mesh.html">mesh</a>. The image points to the world texture. This is the texture we want to apply to the sphere. Behind the scenes NAP loads the image from disk and uploads the pixel data to the GPU. This image is now a texture that can be used by shaders as a sampler texture input. In this particular case we want the world shader to use that texture. The world shader exposes a sampler with the name 'inWorldTexture'. But how do we bind the world texture to the shader? As you can see in the example above: the world texture is not referenced anywhere. For that purpose we use a material. Let's add one:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot;: &quot;nap::Material&quot;,</div><div class="line">    &quot;mID&quot;: &quot;WorldMaterial&quot;,</div><div class="line">    &quot;Uniforms&quot;: [],</div><div class="line">    &quot;Samplers&quot;: </div><div class="line">    [</div><div class="line">        {</div><div class="line">            &quot;Type&quot;: &quot;nap::Sampler2D&quot;,</div><div class="line">            &quot;mID&quot;: &quot;world_input_tex_uniform&quot;,</div><div class="line">            &quot;Name&quot;: &quot;inWorldTexture&quot;,</div><div class="line">            &quot;Texture&quot;: &quot;WorldTexture&quot;</div><div class="line">        }</div><div class="line">    ],</div><div class="line">    &quot;Shader&quot;: &quot;WorldShader&quot;,</div><div class="line">    &quot;BlendMode&quot;: &quot;Opaque&quot;,</div><div class="line">    &quot;DepthMode&quot;: &quot;InheritFromBlendMode&quot;</div><div class="line">},</div></div><!-- fragment --><p>A <a class="el" href="../../d2/de3/classnap_1_1_material.html">material</a> serves a very important function. It allows you to apply the same shader to different objects. Often you only need a limited set of shaders to represent a large set of objects. The same shader can be used to render objects that share the same physical properties, such as a window and a wine glass. Creating separate shaders for each individual object is inefficient. In the example above we create a world material that links to a world shader. NAP creates both the shader and material for you. The only thing left to do is link the 'WorldTexture' to the right shader input exposed by the material.</p>
<p>Every material carries a set of 'Uniforms' and 'Samplers'. Material 'Uniforms' allow you to bind values to specific inputs of a shader. Samplers allow you to bind textures to specific inputs of a shader. This material binds 'WorldTexture' to 'inWorldTexture'. When you apply this material to a mesh (in this case the sphere) the renderer binds the texture to the right input of the shader with, as a result, a sphere that looks like planet earth. NAP validates that the shader exposes a texture input called 'inWorldTexture' and the 'WorldTexture' is loaded and valid. Initialization fails when the world texture can't be loaded or the shader doesn't have an input called 'inWorldTexture'. In both cases an error message is generated.</p>
<p>You now have a material that you can apply to your sphere. But we don't have a scene that represents the objects in space. Without that structure the renderer doesn't know where to place the sphere and what material to apply to the sphere. We therefore create a simple scene structure that holds both the camera and sphere to render:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot; : &quot;nap::Scene&quot;,</div><div class="line">    &quot;mID&quot;: &quot;Scene&quot;,     </div><div class="line">    &quot;Entities&quot; : </div><div class="line">    [</div><div class="line">        {</div><div class="line">            &quot;Entity&quot; : &quot;World&quot;</div><div class="line">        },</div><div class="line">        {</div><div class="line">            &quot;Entity&quot; : &quot;Camera&quot;</div><div class="line">        }</div><div class="line">    ]</div><div class="line">},</div></div><!-- fragment --><p>And define our 'World':</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot; : &quot;nap::Entity&quot;,</div><div class="line">    &quot;mID&quot;: &quot;World&quot;,</div><div class="line">    &quot;Components&quot; : </div><div class="line">    [</div><div class="line">        {</div><div class="line">            &quot;Type&quot; : &quot;nap::RenderableMeshComponent&quot;,</div><div class="line">            &quot;mID&quot;: &quot;Renderable Mesh Component&quot;,</div><div class="line">            &quot;Mesh&quot; : &quot;WorldMesh&quot;,</div><div class="line">            &quot;MaterialInstance&quot; : </div><div class="line">            {</div><div class="line">                &quot;mID&quot;: &quot;WorldMaterialInstance&quot;,</div><div class="line">                &quot;Material&quot;: &quot;WorldMaterial&quot;</div><div class="line">            }</div><div class="line">        },</div><div class="line">        {</div><div class="line">            &quot;Type&quot; : &quot;nap::TransformComponent&quot;,</div><div class="line">            &quot;mID&quot;: &quot;Transform Component&quot;</div><div class="line">        },</div><div class="line">        {</div><div class="line">            &quot;Type&quot; : &quot;nap::RotateComponent&quot;,</div><div class="line">            &quot;mID&quot;: &quot;Rotate Component&quot;,</div><div class="line">            &quot;Properties&quot;: </div><div class="line">            {</div><div class="line">                &quot;Axis&quot;: </div><div class="line">                {</div><div class="line">                    &quot;x&quot;: 0.0,</div><div class="line">                    &quot;y&quot;: 1.0,</div><div class="line">                    &quot;z&quot;: 0.0</div><div class="line">                },</div><div class="line">                &quot;Speed&quot;: 0.1,</div><div class="line">                &quot;Offset&quot;: 2.0</div><div class="line">            }</div><div class="line">        }       </div><div class="line">    ]</div><div class="line">},</div></div><!-- fragment --><p>Before we add the camera it's good to take a closer look at the <a class="el" href="../../d4/d61/classnap_1_1_renderable_mesh_component.html">renderable mesh component</a>. As mentioned before, this component binds both a mesh and material together. When doing so it performs a very important task: it makes sure that the mesh can be rendered to a render target. This component also pushes all the material properties to the GPU before rendering the mesh. The <a class="el" href="../../de/d34/classnap_1_1_transform_component.html">transform component</a> positions the 'World' at the origin of the scene and the <a class="el" href="../../d1/de7/classnap_1_1_rotate_component.html">rotate component</a> rotates the 'World' around the y axis once every 10 seconds. Last thing to do is add a <a class="el" href="../../d6/d3d/classnap_1_1_persp_camera_component.html">camera</a>, we place it five units back from the origin of the scene to ensure the world is visible:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot; : &quot;nap::Entity&quot;,</div><div class="line">    &quot;mID&quot;: &quot;Camera&quot;,</div><div class="line">    &quot;Components&quot; : </div><div class="line">    [</div><div class="line">        {</div><div class="line">            &quot;Type&quot; : &quot;nap::PerspCameraComponent&quot;,</div><div class="line">            &quot;Properties&quot;: </div><div class="line">            {</div><div class="line">                &quot;FieldOfView&quot;: 45.0,</div><div class="line">                &quot;NearClippingPlane&quot; : 1,</div><div class="line">                &quot;FarClippingPlane&quot; : 1000.0</div><div class="line">            }</div><div class="line">        },</div><div class="line">        {</div><div class="line">            &quot;Type&quot; : &quot;nap::TransformComponent&quot;,</div><div class="line">            &quot;Properties&quot;: </div><div class="line">            {</div><div class="line">                &quot;Translate&quot;: </div><div class="line">                {</div><div class="line">                    &quot;x&quot;: 0.0,</div><div class="line">                    &quot;y&quot;: 0.0,</div><div class="line">                    &quot;z&quot;: 5.0</div><div class="line">                }           </div><div class="line">            }</div><div class="line">        }</div><div class="line">    ]</div><div class="line">}</div></div><!-- fragment --><p>You're now ready to load this file and fetch the created resources. You need those to render the world later on:</p>
<div class="fragment"><div class="line"><span class="keywordtype">bool</span> ExampleApp::init(utility::ErrorState&amp; error)</div><div class="line">{</div><div class="line">    <span class="comment">// Retrieve services</span></div><div class="line">    mRenderService = getCore().getService&lt;<a class="code" href="../../d5/dc6/classnap_1_1_render_service.html">nap::RenderService</a>&gt;();</div><div class="line">    mSceneService  = getCore().getService&lt;<a class="code" href="../../dc/db5/classnap_1_1_scene_service.html">nap::SceneService</a>&gt;();</div><div class="line"></div><div class="line">    <span class="comment">// Get resource manager</span></div><div class="line">    mResourceManager = getCore().getResourceManager();</div><div class="line"></div><div class="line">    <span class="comment">// Extract loaded resources</span></div><div class="line">    mRenderWindow = mResourceManager-&gt;findObject&lt;<a class="code" href="../../d6/d4f/classnap_1_1_render_window.html">nap::RenderWindow</a>&gt;(<span class="stringliteral">&quot;Window0&quot;</span>);</div><div class="line"></div><div class="line">    <span class="comment">// Find the world and camera entities</span></div><div class="line">    ObjectPtr&lt;Scene&gt; scene = mResourceManager-&gt;findObject&lt;Scene&gt;(<span class="stringliteral">&quot;Scene&quot;</span>);</div><div class="line"></div><div class="line">    mWorldEntity  = scene-&gt;findEntity(<span class="stringliteral">&quot;World&quot;</span>);</div><div class="line">    mCameraEntity = scene-&gt;findEntity(<span class="stringliteral">&quot;Camera&quot;</span>);</div><div class="line">}</div></div><!-- fragment --><p>And in the render call of your application you explicitly tell the renderer to render your 'World' at the origin (defined by it's transform) with the right material:</p>
<div class="fragment"><div class="line"><span class="comment">// Called when the window is going to render</span></div><div class="line"><span class="keywordtype">void</span> ExampleApp::render()</div><div class="line">{</div><div class="line">    <span class="comment">// Signal the beginning of a new frame, allowing it to be recorded.</span></div><div class="line">    mRenderService-&gt;beginFrame();</div><div class="line"></div><div class="line">    <span class="comment">// Begin recording the render commands for the main render window</span></div><div class="line">    <span class="keywordflow">if</span> (mRenderService-&gt;beginRecording(*mRenderWindow))</div><div class="line">    {</div><div class="line">        <span class="comment">// Begin the render pass</span></div><div class="line">        mRenderWindow-&gt;beginRendering();</div><div class="line"></div><div class="line">        <span class="comment">// Find the world and add as an object to render</span></div><div class="line">        std::vector&lt;nap::RenderableComponentInstance*&gt; components_to_render;</div><div class="line">        <a class="code" href="../../d9/d73/classnap_1_1_renderable_mesh_component_instance.html">nap::RenderableMeshComponentInstance</a>&amp; renderable_world = mWorldEntity-&gt;<a class="code" href="../../d9/df2/classnap_1_1_component_instance.html#ae6265a431e0348f6df8d19bfc8184538">getComponent</a>&lt;<a class="code" href="../../d9/d73/classnap_1_1_renderable_mesh_component_instance.html">nap::RenderableMeshComponentInstance</a>&gt;();</div><div class="line">        components_to_render.emplace_back(&amp;renderable_world);</div><div class="line"></div><div class="line">        <span class="comment">// Find the perspective camera</span></div><div class="line">        <a class="code" href="../../d2/d87/classnap_1_1_persp_camera_component_instance.html">nap::PerspCameraComponentInstance</a>&amp; persp_camera = mPerspectiveCamEntity-&gt;<a class="code" href="../../d9/df2/classnap_1_1_component_instance.html#ae6265a431e0348f6df8d19bfc8184538">getComponent</a>&lt;<a class="code" href="../../d2/d87/classnap_1_1_persp_camera_component_instance.html">nap::PerspCameraComponentInstance</a>&gt;();</div><div class="line"></div><div class="line">        <span class="comment">// Render the world with the right camera directly to screen</span></div><div class="line">        mRenderService-&gt;renderObjects(*mRenderWindow, persp_camera, components_to_render);</div><div class="line"></div><div class="line">        <span class="comment">// End the render pass</span></div><div class="line">        mRenderWindow-&gt;endRendering();</div><div class="line"></div><div class="line">        <span class="comment">// End recording</span></div><div class="line">        mRenderService-&gt;endRecording();</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="comment">// Signal the end of the frame</span></div><div class="line">    mRenderService-&gt;endFrame();</div><div class="line">}</div></div><!-- fragment --><p>That's it, you should see a rotating textured sphere in the center of your viewport. This example tried to cover the basics of rendering with NAP but as you might have suspected: modern day rendering is a vast and complex subject. NAP's philosophy is to be open; it doesn't render for you. What NAP does best is getting you set up with the building blocks to render complex scenes. This also applies to many other facets of the framework. But in return you get a very open engine that allows you to render most things without having to write thousands of lines of code.</p>
<p>To get a better understanding of rendering with NAP continue reading or play around with a render demo that ships with NAP. This example is part of the 'HelloWorld' demo:</p>
<div class="image">
<img src="../../content/helloworld.png" alt="helloworld.png"/>
</div>
<h1><a class="anchor" id="meshes"></a>
Meshes </h1>
<h2><a class="anchor" id="creating_meshes"></a>
Creating Meshes </h2>
<p>The underlying resource of all mesh types is the <a class="el" href="../../dd/dac/classnap_1_1_i_mesh.html">IMesh</a>. The <code>IMesh</code> does only one thing: provide the renderer with a <a class="el" href="../../da/d17/classnap_1_1_mesh_instance.html">mesh instance</a>. The mesh instance contains the actual data that is drawn. The following resources create a mesh instance:</p>
<h3><a class="anchor" id="mesh_from_file"></a>
Mesh From File</h3>
<p>The <a class="el" href="../../db/d48/classnap_1_1_mesh_from_file.html">MeshFromFile</a> loads a mesh from an external file. NAP only supports the FBX file format and automatically converts any .fbx file in to a .mesh file using the FBX converter tool. The result is a heavily compressed binary file. The FBX converter runs automatically after compilation and only converts .fbx files when new. Alternatively you can run the tool from the command line. Type &ndash;help for instructions. If an .fbx file contains multiple meshes each mesh is stored into an individual .mesh file.</p>
<p>Here is an example:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot; : &quot;nap::MeshFromFile&quot;,</div><div class="line">    &quot;mID&quot;: &quot;CarMesh&quot;,</div><div class="line">    &quot;Path&quot;: &quot;car.mesh&quot;</div><div class="line">}</div></div><!-- fragment --><h3><a class="anchor" id="predefined_shapes"></a>
Predefined Shapes</h3>
<p>A few simple shapes (such as a <a class="el" href="../../de/dd6/classnap_1_1_plane_mesh.html">plane</a>, <a class="el" href="../../d6/d7b/classnap_1_1_sphere_mesh.html">sphere</a> or <a class="el" href="../../df/de6/classnap_1_1_box_mesh.html">box</a>) can be created directly using configurable parameters:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot; : &quot;nap::SphereMesh&quot;,</div><div class="line">    &quot;mID&quot;: &quot;SphereMesh&quot;,</div><div class="line">    &quot;Radius&quot; : 5,</div><div class="line">    &quot;Rings&quot; : 50,</div><div class="line">    &quot;Sectors&quot; : 50</div><div class="line">},</div><div class="line">{</div><div class="line">    &quot;Type&quot; : &quot;nap::PlaneMesh&quot;,</div><div class="line">    &quot;mID&quot;: &quot;PlaneMesh&quot;,</div><div class="line">    &quot;Rows&quot; : 128,</div><div class="line">    &quot;Columns&quot; : 128</div><div class="line">},</div><div class="line">{</div><div class="line">    &quot;Type&quot; : &quot;nap::BoxMesh&quot;.</div><div class="line">    &quot;mID&quot; : &quot;BoxMesh&quot;,</div><div class="line">    &quot;Size&quot;: </div><div class="line">    {</div><div class="line">        &quot;x&quot;: 1.0,</div><div class="line">        &quot;y&quot;: 1.0,</div><div class="line">        &quot;z&quot;: 1.0</div><div class="line">    }</div><div class="line">}</div></div><!-- fragment --><h3><a class="anchor" id="mesh_resource"></a>
Mesh Resource</h3>
<ul>
<li>The <a class="el" href="../../d0/d32/classnap_1_1_mesh.html">Mesh</a> resource can be used to explicitly define the contents of a mesh in a JSON file. Below you see an example of a mesh in the shape of a plane. This mesh contains four vertices. The plane has a position and UV attribute. The triangles are formed as a TriangleStrip:</li>
</ul>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot; : &quot;nap::Mesh&quot;,</div><div class="line">    &quot;mID&quot; : &quot;CustomPlaneMesh&quot;,</div><div class="line">    &quot;Properties&quot; : {</div><div class="line">        &quot;NumVertices&quot; : 4,</div><div class="line">        &quot;Shapes&quot; : [</div><div class="line">            {</div><div class="line">                &quot;DrawMode&quot; : &quot;TriangleStrip&quot;</div><div class="line">            }</div><div class="line">        ],</div><div class="line">        &quot;Attributes&quot; : [</div><div class="line">            {</div><div class="line">                &quot;Type&quot; : &quot;nap::Vec3VertexAttribute&quot;,</div><div class="line">                &quot;AttributeID&quot; : &quot;Position&quot;,</div><div class="line">                &quot;Data&quot; : [</div><div class="line">                    { &quot;x&quot;: -0.5,    &quot;y&quot;: -0.5, &quot;z&quot;: 0.0 },</div><div class="line">                    { &quot;x&quot;:  0.5,    &quot;y&quot;: -0.5,  &quot;z&quot;: 0.0 },</div><div class="line">                    { &quot;x&quot;: -0.5,    &quot;y&quot;:  0.5,  &quot;z&quot;: 0.0 },</div><div class="line">                    { &quot;x&quot;:  0.5,    &quot;y&quot;:  0.5,  &quot;z&quot;: 0.0 }</div><div class="line">                ]</div><div class="line">            },</div><div class="line">            {</div><div class="line">                &quot;Type&quot; : &quot;nap::Vec3VertexAttribute&quot;,</div><div class="line">                &quot;AttributeID&quot; : &quot;UV0&quot;,</div><div class="line">                &quot;Data&quot; : [</div><div class="line">                    { &quot;x&quot;: 0.0,     &quot;y&quot;: 0.0,   &quot;z&quot;: 0.0 },</div><div class="line">                    { &quot;x&quot;: 1.0,     &quot;y&quot;: 0.0,   &quot;z&quot;: 0.0 },</div><div class="line">                    { &quot;x&quot;: 0.0,     &quot;y&quot;: 1.0,   &quot;z&quot;: 0.0 },</div><div class="line">                    { &quot;x&quot;: 1.0,     &quot;y&quot;: 1.0,   &quot;z&quot;: 0.0 }</div><div class="line">                ]</div><div class="line">            }</div><div class="line">        ],</div><div class="line">        &quot;Indices&quot; : [</div><div class="line">            0,</div><div class="line">            1,</div><div class="line">            3,</div><div class="line">            0,</div><div class="line">            3,</div><div class="line">            2</div><div class="line">        ]</div><div class="line">    }</div><div class="line">}</div></div><!-- fragment --><h3><a class="anchor" id="custom_mesh"></a>
Custom Mesh C++</h3>
<p>You can create your own custom or procedural mesh in code. Both the 'dynamicgeo' and 'heightmap' demo show you how to do this. In the following example we define a new mesh. On initialization the instance is created. For the mesh to behave and render correctly we add a set of attributes. In this case 'Position', 'uv', 'id' and 'color'. The mesh contains no actual (initial) vertex data. The vertex data grows / shrinks over time based on the number of active particles in the scene. For a more complete example refer to the 'dynamicgeo' demo.</p>
<div class="fragment"><div class="line"><span class="keyword">class </span>ParticleMesh : <span class="keyword">public</span> IMesh</div><div class="line">{</div><div class="line"><span class="keyword">public</span>:</div><div class="line"></div><div class="line">    ParticleMesh(Core&amp; core) : mRenderService(core.getService&lt;RenderService&gt;()) { }</div><div class="line"></div><div class="line"></div><div class="line">    <span class="keywordtype">bool</span> init(utility::ErrorState&amp; errorState)</div><div class="line">    {</div><div class="line">        <span class="comment">// Create the mesh instance</span></div><div class="line">        mMeshInstance = std::make_unique&lt;MeshInstance&gt;(*mRenderService);</div><div class="line"></div><div class="line">        <span class="comment">// Because the mesh is populated dynamically we set the initial amount of vertices to be 0</span></div><div class="line">        mMeshInstance-&gt;setNumVertices(0);</div><div class="line">        mMeshInstance-&gt;setUsage(EMeshDataUsage::DynamicWrite);</div><div class="line">        mMeshInstance-&gt;setDrawMode(EDrawMode::Triangles);</div><div class="line">        mMeshInstance-&gt;setCullMode(ECullMode::None);</div><div class="line"></div><div class="line">        <span class="comment">// Allocate room for 1000 vertices</span></div><div class="line">        mMeshInstance-&gt;reserveVertices(1000);</div><div class="line"></div><div class="line">        <span class="comment">// Add mesh attributes</span></div><div class="line">        mMeshInstance-&gt;getOrCreateAttribute&lt;glm::vec3&gt;(vertexid::position);</div><div class="line">        mMeshInstance-&gt;getOrCreateAttribute&lt;glm::vec3&gt;(vertexid::getUVName(0));</div><div class="line">        mMeshInstance-&gt;getOrCreateAttribute&lt;glm::vec4&gt;(vertexid::getColorName(0));</div><div class="line">        mMeshInstance-&gt;getOrCreateAttribute&lt;<span class="keywordtype">float</span>&gt;(<span class="stringliteral">&quot;pid&quot;</span>);</div><div class="line"></div><div class="line">        <span class="comment">// Create the shape that connects the vertices</span></div><div class="line">        MeshShape&amp; shape = mMeshInstance-&gt;createShape();</div><div class="line"></div><div class="line">        <span class="comment">// Reserve CPU memory for the particle geometry indices.</span></div><div class="line">        shape.reserveIndices(1000);</div><div class="line"></div><div class="line">        <span class="comment">// Initialize the instance</span></div><div class="line">        <span class="keywordflow">return</span> mMeshInstance-&gt;init(errorState);</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="keyword">virtual</span> MeshInstance&amp; getMeshInstance()<span class="keyword"> override                    </span>{ <span class="keywordflow">return</span> *mMeshInstance; }</div><div class="line"></div><div class="line">    <span class="keyword">virtual</span> <span class="keyword">const</span> MeshInstance&amp; getMeshInstance()<span class="keyword"> const override        </span>{ <span class="keywordflow">return</span> *mMeshInstance; }</div><div class="line"></div><div class="line"><span class="keyword">private</span>:</div><div class="line">    std::unique_ptr&lt;MeshInstance&gt; mMeshInstance = <span class="keyword">nullptr</span>;</div><div class="line">};</div></div><!-- fragment --><h2><a class="anchor" id="mesh_format"></a>
The Mesh Format </h2>
<p>The mesh instance format is best explained by an example. Consider a mesh that represents the letter ‘P’:</p>
<div class="image">
<img src="../../content/mesh_shapes.png" alt="mesh_shapes.png"/>
</div>
<p>This letter contains a list of 24 points. However, the mesh is split up into two separate pieces: the closed line that forms the outer shape and the closed line that forms the inner shape. The points of both shapes are represented by the blue and orange colors.</p>
<p>Every mesh instance contains a list of points (vertices). Each vertex can have multipe attributes such as a normal, a UV coordinate and a color. In this example the mesh holds a list of exactly 24 vertices. To add each individual line to the mesh we create a <a class="el" href="../../d3/d98/classnap_1_1_mesh_shape.html">shape</a>. The shape tells the system two things:</p>
<ul>
<li>How the vertices are connected using a list of indices. In this case vertices 0-12 define the outer shape, vertices 13-23 define the inner shape.</li>
<li>How the GPU interprets the indices, ie: how are the points connected? For this example we tell the GPU to connect the vertices as a single line using <code>LineStrip</code></li>
</ul>
<p>Within a single mesh you can define multiple shapes that share the same set of vertices (points). It is allowed to share vertices between shapes and it is allowed to define a single mesh with different types of shapes. Take a sphere for example. The vertices can be used to define both the sphere as a triangle mesh and the normals of that sphere as a set of individual lines. The normals are rendered as lines (instead of triangles) but share (part of) the underlying vertex structure. This sphere therefore contains two shapes, one triangle shape (to draw the sphere) and one line shape (to draw the normals).</p>
<p>All common shapes are supported: <code>Points</code>, <code>Lines</code>, <code>LineStrip</code>, <code>Triangles</code>, <code>TriangleStrip</code> and <code>TriangleFan</code>.</p>
<p>As a user you can work on individual vertices or on the vertices associated with a specific shape. Often its necessary to walk over all the shapes that constitute a mesh. On a higher level NAP provides utility functions (such as computeNormals and reverseWindingOrder) to operate on a mesh as a whole. But for custom work NAP provides a very convenient and efficient <a class="el" href="../../d2/d3d/classnap_1_1_triangle_iterator.html">iterator</a> that is capable of looping over all the triangles within multiple shapes. This ensures that as a user you don’t need to know about the internal connectivity of the various shapes. Consider this example:</p>
<div class="fragment"><div class="line"><span class="comment">// fetch uv attribute</span></div><div class="line"><a class="code" href="../../d3/d14/namespacenap.html#ad862aab0442c9226952c61b8a2a37be4">Vec3VertexAttribute</a>* uv_nattr = mesh.findAttribute&lt;glm::vec3&gt;(vertexid::getUVName(0));</div><div class="line"></div><div class="line"><span class="comment">// fetch uv center attribute </span></div><div class="line"><a class="code" href="../../d3/d14/namespacenap.html#ad862aab0442c9226952c61b8a2a37be4">Vec3VertexAttribute</a>* uv_cattr = mesh.findAttribute&lt;glm::vec3&gt;(<span class="stringliteral">&quot;uvcenter&quot;</span>);</div><div class="line"></div><div class="line"><span class="comment">// Create triangle iterator</span></div><div class="line">TriangleShapeIterator shape_iterator(*mMeshInstance);</div><div class="line"></div><div class="line"><span class="comment">// Iterate over all the triangles and calculate average uv value for every triangle</span></div><div class="line">TriangleIterator tri_iterator(*mMeshInstance);</div><div class="line"><span class="keywordflow">while</span> (!tri_iterator.isDone())</div><div class="line">{</div><div class="line">    <span class="comment">// Get triangle</span></div><div class="line">    Triangle triangle = tri_iterator.next();</div><div class="line"></div><div class="line">    <span class="comment">// Get uv values associated with triangle</span></div><div class="line">    TriangleData&lt;glm::vec3&gt; uvTriangleData = triangle.getVertexData(*uv_nattr);</div><div class="line"></div><div class="line">    <span class="comment">// Calculate uv average</span></div><div class="line">    glm::vec3 uv_avg = { 0.0, 0.0, 0.0 };</div><div class="line">    uv_avg += uvTriangleData.first();</div><div class="line">    uv_avg += uvTriangleData.second();</div><div class="line">    uv_avg += uvTriangleData.third();</div><div class="line">    uv_avg /= 3.0f;</div><div class="line"></div><div class="line">    <span class="comment">// Set average to all vertices associated with triangle</span></div><div class="line">    triangle.setVertexData(*uv_cattr, uv_avg);</div><div class="line">}</div></div><!-- fragment --><h2><a class="anchor" id="mesh_usage"></a>
Mesh Usage </h2>
<p>The <a class="el" href="../../d3/d14/namespacenap.html#acf783615da7db48794fbc2f8fbce87bf">mesh data usage flag</a> determines how the mesh data is used at runtime. A <code>Static</code> mesh is uploaded from the CPU to the GPU exactly once. This allows the system to remove unused buffers after the upload is complete. If there is the need to update a mesh more frequently, even once after upload, it is required the usage is set to <code>DynamicWrite</code>. Note that static meshes are often placed in a different cache on the GPU, not accessible by the CPU, which allows for faster drawing times. <code>DynamicWrite</code> meshes are uploaded into shared CPU / GPU memory and are therefore slower to draw. Keep this in mind when selecting the appropriate data use.</p>
<h1><a class="anchor" id="text"></a>
Text </h1>
<p>Rendering text is similar to rendering meshes, but instead of a mesh every <a class="el" href="../../dc/d02/classnap_1_1_renderable2_d_text_component.html">component</a> that can draw text links to a <a class="el" href="../../da/dad/classnap_1_1_font.html">font</a>. You can change text at runtime by calling setText() or declare a line of text in json.</p>
<p>The <a class="el" href="../../da/dad/classnap_1_1_font.html">font resource</a> loads a font file from disk. All well known font formats are supported, including ttf en otf. Fonts can scale up to any size and are always rendered in their native resolution when using the <a class="el" href="../../dc/d02/classnap_1_1_renderable2_d_text_component.html">Renderable2DTextComponent</a>. This ensures a perfect text representation at every size.</p>
<p>There are currently two components that can draw text to screen: <a class="el" href="../../dc/d02/classnap_1_1_renderable2_d_text_component.html">Renderable2DTextComponent</a> and <a class="el" href="../../d2/d4e/classnap_1_1_renderable3_d_text_component.html">Renderable3DTextComponent</a>. When rendering text in screen space use the 2D version, when placing text somewhere in the world use the 3D version.</p>
<p>The <a class="el" href="../../dc/d02/classnap_1_1_renderable2_d_text_component.html">Renderable2DTextComponent</a> has a draw call that can be used to draw text directly at a specific location. The provided coordinates are in screen space (pixels), where 0,0 is the bottom left corner of your screen or back-buffer. Alternatively you can use the <a class="el" href="../../d5/dc6/classnap_1_1_render_service.html">render service</a> to render your 2D text. This is similar to rendering meshes. 3D text is always rendered using the render-service. The component that renders text uses it's own hard coded <a class="el" href="../../d4/d6c/classnap_1_1_font_shader.html">shader</a> so you don't have to link in a custom material.</p>
<p>The HelloWorld demo shows you how to set this up.</p>
<h1><a class="anchor" id="materials"></a>
Materials and Shaders </h1>
<p>A <a class="el" href="../../dd/d44/classnap_1_1_shader.html">shader</a> is a piece of code that is executed on the GPU. You can use shaders to perform many tasks including rendering a mesh to screen or in to a different buffer. The material tells the shader how to execute that piece of code. A material therefore:</p>
<ul>
<li>Defines the mapping between the mesh vertex attributes and the shader vertex attributes</li>
<li>Stores and updates the uniform shader inputs</li>
<li>Stores and updates the sampler shader inputs</li>
<li>Controls render settings such as the blend and depth mode</li>
</ul>
<p>Multiple materials can reference the same shader. You can change the properties of a material on a global (resource) and instance level. To change the properties of a material on an instance you use a <a class="el" href="../../d0/daa/classnap_1_1_material_instance.html">MaterialInstance</a> object. A material instance is used to override uniform and sampler inputs and change the render state of a material. This makes it possible to create a complex material with default attribute mappings and uniform inputs but override specific settings for a specific object.</p>
<p>Imagine you have twenty buttons on your screen that all look the same, but when you move your mouse over a button you want it to light up. You can do this by making a single material that is configured to show a normal button and change the unifom 'color' for the button you are hovering over. Changing the color uniform is done by altering the material instance attribute 'color'.</p>
<h2><a class="anchor" id="vertex_attrs"></a>
Vertex Attributes </h2>
<p>Meshes can contain any number of vertex attributes. How those attributes correspond to vertex attributes in the shader is defined in the material. It is simply a mapping from a mesh attribute ID ('Position') to a shader attribute ID ('in_Position'). Consider this simple .vert shader:</p>
<div class="fragment"><div class="line">uniform mat4 <a class="code" href="../../d4/dff/namespacenap_1_1uniform.html#a54ea6f6a3f54bbe9cce2538e475c7b0d">projectionMatrix</a>;  <span class="comment">//&lt; camera projection matrix</span></div><div class="line">uniform mat4 <a class="code" href="../../d4/dff/namespacenap_1_1uniform.html#a5f63c78461a9dbc60e6807190ab6a9b3">viewMatrix</a>;        <span class="comment">//&lt; camera view matrix (world space location)</span></div><div class="line">uniform mat4 <a class="code" href="../../d4/dff/namespacenap_1_1uniform.html#a69097cc755916870aecb2f8fc2239de3">modelMatrix</a>;       <span class="comment">//&lt; vertex model to world matrix</span></div><div class="line"></div><div class="line">in vec3 in_Position;            <span class="comment">//&lt; in vertex position object space</span></div><div class="line">in vec4 in_Color0;              <span class="comment">//&lt; in vertex color</span></div><div class="line">in vec3 in_UV0;                 <span class="comment">//&lt; in vertex uv channel 0</span></div><div class="line"></div><div class="line">out vec4 pass_Color;            <span class="comment">//&lt; pass color to fragment shader</span></div><div class="line">out vec3 pass_Uvs;              <span class="comment">//&lt; pass uv to fragment shader</span></div><div class="line"></div><div class="line"><span class="keywordtype">void</span> main(<span class="keywordtype">void</span>)</div><div class="line">{</div><div class="line">    <span class="comment">// Calculate vertex position</span></div><div class="line">    gl_Position = <a class="code" href="../../d4/dff/namespacenap_1_1uniform.html#a54ea6f6a3f54bbe9cce2538e475c7b0d">projectionMatrix</a> * <a class="code" href="../../d4/dff/namespacenap_1_1uniform.html#a5f63c78461a9dbc60e6807190ab6a9b3">viewMatrix</a> * <a class="code" href="../../d4/dff/namespacenap_1_1uniform.html#a69097cc755916870aecb2f8fc2239de3">modelMatrix</a> * vec4(in_Position, 1.0);</div><div class="line"></div><div class="line">    <span class="comment">// Pass color and uv&#39;s </span></div><div class="line">    pass_Color = in_Color;</div><div class="line">    pass_Uvs = in_UV;</div><div class="line">}</div></div><!-- fragment --><p>This (vertex) shader doesn't do a lot. It transforms the vertex position and passes the vertex color and UV coordinates to the fragment shader. The vertex attributes are called 'in_Position', 'in_Color0' and 'in_UV0'. Next we bind the mesh vertex attributes to the shader vertex inputs using a material. To do that we provide the material with a table that binds the two together:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot; : &quot;nap::Material&quot;,</div><div class="line">    &quot;mID&quot;: &quot;MyMaterial&quot;,</div><div class="line">    &quot;Shader&quot;: &quot;MyShader&quot;,</div><div class="line">    &quot;VertexAttributeBindings&quot; : </div><div class="line">    [</div><div class="line">        {</div><div class="line">            &quot;MeshAttributeID&quot;: &quot;Position&quot;,              //&lt; Mesh position vertex attribute</div><div class="line">            &quot;ShaderAttributeID&quot;: &quot;in_Position&quot;          //&lt; Shader position input</div><div class="line">        },</div><div class="line">        {</div><div class="line">            &quot;MeshAttributeID&quot;: &quot;UV0&quot;,                   //&lt; Mesh uv vertex attribute</div><div class="line">            &quot;ShaderAttributeID&quot;: &quot;in_UV0&quot;               //&lt; Shader uv input</div><div class="line">        },</div><div class="line">        {</div><div class="line">            &quot;MeshAttributeID&quot;: &quot;Color0&quot;,                //&lt; Mesh color vertex attribute</div><div class="line">            &quot;ShaderAttributeID&quot;: &quot;in_Color0&quot;            //&lt; Shader color input</div><div class="line">        }</div><div class="line">    ]       </div><div class="line">}</div></div><!-- fragment --><p>The shader is always leading when it comes to mapping vertex attributes. This means that all the exposed shader vertex attributes need to be present in the material and on the mesh. It is also required that they are of the same internal type. To make things a bit more manageable and convenient: a mesh can contain more attributes than exposed by a shader. The mapping (as demonstrated above) can also contain more entries than exposed by a shader. This makes it easier to create common mappings and iterate on your shader. It would be inconvenient if the application yields an error when you comment out attributes in your shader. Even worse, if certain code in the shader is optimized out while working on it, certain inputs might not exist anymore. In these cases you don't want the initialization of your material to fail.</p>
<h2><a class="anchor" id="default_attrs"></a>
Default Vertex Attributes </h2>
<p>Meshes that are loaded from file contain a fixed set of vertex attributes:</p><ul>
<li>Position (required)</li>
<li>Normal (optional)</li>
<li>Tangent (auto generated when not available)</li>
<li>Bitangents (auto generated when not available)</li>
<li>Multiple UV channels (optional)</li>
<li>Multiple Color channels (optional)</li>
</ul>
<p>The names of the default vertex attributes can be retreived using a set of <a class="el" href="../../df/d2a/renderglobals_8h_source.html">global variables</a>.</p>
<div class="fragment"><div class="line"><a class="code" href="../../d3/db4/namespacenap_1_1vertexid.html#a64c7362b14cffabd0b691ae0668628b9">nap::vertexid::position</a></div><div class="line"><a class="code" href="../../d3/db4/namespacenap_1_1vertexid.html#a320448ab71b9069500ba41d2cb5d0c41">nap::vertexid::normal</a></div><div class="line"><a class="code" href="../../d3/db4/namespacenap_1_1vertexid.html#a9b6888db093d1ca2b8b305b45a2a998d">nap::vertexid::color</a></div><div class="line"><a class="code" href="../../d3/db4/namespacenap_1_1vertexid.html#ae5b83fb55548e95d63c681ee15383479">nap::vertexid::uv</a></div><div class="line"><span class="comment">//etc...</span></div></div><!-- fragment --><p>Every material creates a default mapping if no mapping is provided. The UV and Color attributes are included up to four channels. Default shader input names can be retrieved using a set of <a class="el" href="../../df/d2a/renderglobals_8h_source.html">global variables</a>, similar to vertex attributes:</p>
<div class="fragment"><div class="line"><a class="code" href="../../db/dc1/namespacenap_1_1vertexid_1_1shader.html#a64c7362b14cffabd0b691ae0668628b9">nap::vertexid::shader::position</a></div><div class="line"><a class="code" href="../../db/dc1/namespacenap_1_1vertexid_1_1shader.html#a320448ab71b9069500ba41d2cb5d0c41">nap::vertexid::shader::normal</a></div><div class="line"><a class="code" href="../../db/dc1/namespacenap_1_1vertexid_1_1shader.html#a9b6888db093d1ca2b8b305b45a2a998d">nap::vertexid::shader::color</a></div><div class="line"><a class="code" href="../../db/dc1/namespacenap_1_1vertexid_1_1shader.html#ae5b83fb55548e95d63c681ee15383479">nap::vertexid::shader::uv</a></div><div class="line"><span class="comment">//etc...</span></div></div><!-- fragment --><p>The following table shows the default mesh to shader vertex bindings:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Mesh  </th><th class="markdownTableHeadCenter">Shader   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">Position  </td><td class="markdownTableBodyCenter">in_Position   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyCenter">Normal  </td><td class="markdownTableBodyCenter">in_Normal   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">Tangent  </td><td class="markdownTableBodyCenter">in_Tangent   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyCenter">Bitangent  </td><td class="markdownTableBodyCenter">in_Bitangent   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">UV0  </td><td class="markdownTableBodyCenter">in_UV0   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyCenter">UV1  </td><td class="markdownTableBodyCenter">in_UV1   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">UV2  </td><td class="markdownTableBodyCenter">in_UV2   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyCenter">UV3  </td><td class="markdownTableBodyCenter">in_UV3   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">Color0  </td><td class="markdownTableBodyCenter">in_Color0   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyCenter">Color1  </td><td class="markdownTableBodyCenter">in_Color1   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">Color2  </td><td class="markdownTableBodyCenter">in_Color2   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyCenter">Color2  </td><td class="markdownTableBodyCenter">in_Color2   </td></tr>
</table>
<h2><a class="anchor" id="uniforms"></a>
Uniforms </h2>
<p>Uniforms are shader input 'values' that can be set using the material interface. Every material stores a value for each uniform in the shader. It is allowed to have more uniforms in the material than the shader. This is similar to vertex attributes with one major exception: not every uniform in the shader needs to be present in the material. If there is no matching uniform, a default uniform will be created internally. Every uniform can be accessed by client code and changed at runtime through the material instance interface. Consider the following <code>font.frag</code> shader example:</p>
<div class="fragment"><div class="line">#version 450 core</div><div class="line"></div><div class="line">in vec3 passUVs;</div><div class="line">uniform sampler2D glyph;</div><div class="line"></div><div class="line">uniform UBO</div><div class="line">{</div><div class="line">    uniform vec3 textColor;             //&lt; Text color input</div><div class="line">} ubo;</div><div class="line"></div><div class="line">// output</div><div class="line">out vec4 out_Color;</div><div class="line"></div><div class="line">void main() </div><div class="line">{</div><div class="line">    // Get alpha from glyph </div><div class="line">    float alpha = texture(glyph, passUVs.xy).r;</div><div class="line"></div><div class="line">    // Use alpha together with text color as fragment output</div><div class="line">    out_Color = vec4(ubo.textColor, alpha);</div><div class="line">}</div></div><!-- fragment --><p>And corresponding JSON:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot;: &quot;nap::Material&quot;,</div><div class="line">    &quot;mID&quot;: &quot;FontMaterial&quot;,</div><div class="line">    &quot;Uniforms&quot;: [</div><div class="line">        {</div><div class="line">            &quot;Type&quot;: &quot;nap::UniformStruct&quot;,</div><div class="line">            &quot;mID&quot;: &quot;nap::UniformStruct&quot;,</div><div class="line">            &quot;Name&quot;: &quot;UBO&quot;,</div><div class="line">            &quot;Uniforms&quot;: [</div><div class="line">                {</div><div class="line">                    &quot;Type&quot;: &quot;nap::UniformVec3&quot;,</div><div class="line">                    &quot;mID&quot;: &quot;UniformVec3&quot;,</div><div class="line">                    &quot;Name&quot;: &quot;textColor&quot;,</div><div class="line">                    &quot;Value&quot;: {</div><div class="line">                        &quot;x&quot;: 1.0,</div><div class="line">                        &quot;y&quot;: 1.0,</div><div class="line">                        &quot;z&quot;: 1.0</div><div class="line">                    }</div><div class="line">                }</div><div class="line">            ]</div><div class="line">        }</div><div class="line">    ],</div><div class="line">    &quot;Samplers&quot;: [],</div><div class="line">    &quot;Shader&quot;: &quot;FontShader&quot;,</div><div class="line">    &quot;VertexAttributeBindings&quot;: [],</div><div class="line">    &quot;BlendMode&quot;: &quot;AlphaBlend&quot;,</div><div class="line">    &quot;DepthMode&quot;: &quot;InheritFromBlendMode&quot;</div><div class="line">}</div></div><!-- fragment --><p>This material binds the color 'white' to the <code>textColor</code> uniform input of the shader. This means that all the text rendered with this material will be 'white' unless overridden. The <code>textColor</code> uniform value is part of the <code>UBO</code> uniform struct. Every uniform value must be a member of a uniform struct and can't be declared independent from a struct inside a shader. Uniform values can be directly overridden in JSON (using a <a class="el" href="../../d6/d4f/classnap_1_1_material_instance_resource.html">nap::MaterialInstanceResource</a>) or overridden at run-time using code:</p>
<div class="fragment"><div class="line"><span class="comment">// Get &#39;UBO&#39; struct that holds &#39;textColor&#39;</span></div><div class="line"><a class="code" href="../../dd/d44/classnap_1_1_uniform_struct_instance.html">nap::UniformStructInstance</a>* ubo = text_comp.getMaterialInstance().<a class="code" href="../../dd/d44/classnap_1_1_uniform_struct_instance.html#a52b8b4017eb07fd8ec381c49b7bebb00">getOrCreateUniform</a>(<span class="stringliteral">&quot;UBO&quot;</span>);</div><div class="line"></div><div class="line"><span class="comment">// Get text color, creates override if it doesn&#39;t exist</span></div><div class="line"><a class="code" href="../../d7/d60/classnap_1_1_typed_uniform_value_instance.html">nap::UniformVec3Instance</a>* text_color = ubo-&gt;<a class="code" href="../../dd/d44/classnap_1_1_uniform_struct_instance.html#a52b8b4017eb07fd8ec381c49b7bebb00">getOrCreateUniform</a>&lt;<a class="code" href="../../d3/d14/namespacenap.html#a575dfbfdccbc8cb8133638c74cf667b2">UniformVec3Instance</a>&gt;(<span class="stringliteral">&quot;textColor&quot;</span>);</div><div class="line"></div><div class="line"><span class="comment">// Override text color</span></div><div class="line">text_color-&gt;<a class="code" href="../../d7/d60/classnap_1_1_typed_uniform_value_instance.html#afc2b9c60828a75f61849d20ff7c5d301">setValue</a>({1.0f, 0.0f, 0.0f});</div></div><!-- fragment --><p>The snippet above overrides the default text color from white to red at run-time.</p>
<p>Note that uniform value (and sampler) names must be unique accross all shader stages. This means that for this example the <code>UBO.textColor</code> uniform can't be declared in both the '.frag' and '.vert' part of the shader. Doing this will lead to unexpected results. Initialization of the material will fail when you try to bind a value to the wrong type of input.</p>
<h2><a class="anchor" id="samplers"></a>
Samplers </h2>
<p>A sampler binds a texture to a shader input. They are declared independent from uniforms in the shader and don't have to be part of a uniform struct. Consider the following .frag example:</p>
<div class="fragment"><div class="line">#version 450 core</div><div class="line"></div><div class="line">// vertex shader input  </div><div class="line">in vec4 passColor;                      //&lt; frag color</div><div class="line"></div><div class="line">// unfiorm sampler inputs </div><div class="line">uniform sampler2D inTexture;            //&lt; Input Texture</div><div class="line"></div><div class="line">// output</div><div class="line">out vec4 out_Color;</div><div class="line"></div><div class="line">void main() </div><div class="line">{</div><div class="line">    // Extract output color from texture</div><div class="line">    vec3 out_color =  texture(inTexture, passUVs.xy).rgb * passColor.rgb;</div><div class="line"></div><div class="line">    // Set fragment color</div><div class="line">    out_Color =  vec4(out_color, 1.0);</div><div class="line">}</div></div><!-- fragment --><p>And the following JSON:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot;: &quot;nap::Material&quot;,</div><div class="line">    &quot;mID&quot;: &quot;WorldMaterial&quot;,</div><div class="line">    &quot;Uniforms&quot;: [],</div><div class="line">    &quot;Samplers&quot;: [</div><div class="line">        {</div><div class="line">            &quot;Type&quot;: &quot;nap::Sampler2D&quot;,</div><div class="line">            &quot;mID&quot;: &quot;world_input_tex_uniform&quot;,</div><div class="line">            &quot;Name&quot;: &quot;inWorldTexture&quot;</div><div class="line">        }</div><div class="line">    ],</div><div class="line">    &quot;Shader&quot;: &quot;WorldShader&quot;,</div><div class="line">    &quot;VertexAttributeBindings&quot;: [],</div><div class="line">    &quot;BlendMode&quot;: &quot;Opaque&quot;,</div><div class="line">    &quot;DepthMode&quot;: &quot;InheritFromBlendMode&quot;</div><div class="line">}</div></div><!-- fragment --><p>This material binds the <code>WorldTexture</code> resource to the <code>inTexture</code> sampler of the shader. All objects rendered with this material will use this texture as input unless overridden. Samplers can be directly overridden in JSON (using a <a class="el" href="../../d6/d4f/classnap_1_1_material_instance_resource.html">nap::MaterialInstanceResource</a>) or overridden at run-time using code:</p>
<div class="fragment"><div class="line"><span class="comment">// Get or create sampler override</span></div><div class="line"><a class="code" href="../../d0/daa/classnap_1_1_material_instance.html">nap::MaterialInstance</a>&amp; material = render_comp.getMaterialInstance();</div><div class="line">Sampler2DInstance* sampler = material.<a class="code" href="../../d0/daa/classnap_1_1_material_instance.html#aee48f323f8bebca3d01d150f1653ad5c">getOrCreateSampler</a>&lt;Sampler2DInstance&gt;(<span class="stringliteral">&quot;inTexture&quot;</span>);</div><div class="line"></div><div class="line"><span class="comment">// Update texture</span></div><div class="line">sampler-&gt;setTexture(newTexture);</div></div><!-- fragment --><h2><a class="anchor" id="blending"></a>
Color Blending </h2>
<p>Materials also control the <a class="el" href="../../d3/d14/namespacenap.html#a3359115af439dff42cdf2b23f5c5c4b0">blend</a> and <a class="el" href="../../d3/d14/namespacenap.html#ae67f8c5db2fa79256b62c898c4b8130f">depth</a> state of a material before rendering an object to a target. The blend state specifies how a color that is rendered using a shader is combined into the target buffer. Three modes are available:</p>
<ul>
<li>Opaque: The shader overwrites the target value</li>
<li>AlphaBlend: The alpha value is used to blend between the current and target value</li>
<li>Additive: The shader output is added to the target value</li>
</ul>
<h2><a class="anchor" id="depth"></a>
Depth </h2>
<p>The <a class="el" href="../../d3/d14/namespacenap.html#ae67f8c5db2fa79256b62c898c4b8130f">depth</a> state controls how the z-buffer is treated. These modes are available:</p>
<ul>
<li>ReadWrite: The z output value is tested against the z-buffer. If the test fails, the pixel is not written. If the test succeeds, the new z-value is written back into the z-buffer.</li>
<li>ReadOnly: The z output value is tested against the z-buffer. If the test fails, the pixel is not written. The current z-value is never written back to the z-buffer.</li>
<li>WriteOnly: The z buffer always overwrites the current z value with the new z value.</li>
<li>NoReadWrite: The z buffer is never tested and therefore not updated.</li>
<li>InheritFromBlendMode: This is a special mode that determines how the z-buffer is treated based on the blend mode. For Opaque blend modes ReadWrite is used. For the other (transparent) modes ReadOnly is used. Transparent objects generally want to use the z-buffer but not use it.</li>
</ul>
<p>You can specify the GPU state for material resources and material instances.</p>
<h2><a class="anchor" id="renderwithmaterials"></a>
Rendering Meshes </h2>
<p>The <a class="el" href="../../d4/d61/classnap_1_1_renderable_mesh_component.html">RenderableMeshComponent</a> is responsible for rendering a mesh with a material.</p>
<p>To render an object you need to combine a mesh with a material instance. This combination is called a <a class="el" href="../../df/d52/classnap_1_1_renderable_mesh.html">RenderableMesh</a> and is created by the renderable mesh component. Every mesh / material combination is validated by the system. An error is generated when the mesh does not contain the attributes that are required by the shader. In most cases the renderable mesh is created by the system for you. This happens when you link to a mesh and material from a renderable mesh component. The renderable mesh is automatically created when the component is initialized. When initialization succeeds the component is able to render all the shapes in the mesh instance. The <a class="el" href="../../dd/d9b/rendering.html#render_example">example</a> at the top of this page shows you how to set this up.</p>
<p>You can switch between materials and meshes by providing the renderable mesh component with a different renderable mesh. When you want to switch only the material you can create new renderable mesh by calling <a class="el" href="../../d9/d73/classnap_1_1_renderable_mesh_component_instance.html#ace734627c0f76a438e5134f8403793b9">createRenderableMesh()</a> using the existing mesh and a different material. Using this construct you can change a material, mesh or both. The mesh / material combination will be validated when creating a new renderable mesh. It is strongly recommended to create all selectable mesh / material combinations on initialization. This ensures that you can safely swap them at run time. The video modulation demo shows you how to create and switch between a selection of meshes at run-time.</p>
<h1><a class="anchor" id="textures"></a>
Textures </h1>
<p>There are a lot of similarities between meshes and <a class="el" href="../../d6/d0e/classnap_1_1_texture2_d.html">textures</a>. Both can be loaded from file and created (or updated) using the CPU. There are however some operations that only apply to textures:</p>
<ul>
<li>Textures can be read back from the GPU into CPU memory. Synchronous and asynchronously.</li>
<li>Textures don't require a CPU data representation. For example: the <a class="el" href="../../d6/d5e/classnap_1_1_render_texture2_d.html">render texture</a> only exists on the GPU.</li>
<li>Some textures are continuously updated. This occurs when working with video or image sequences.</li>
</ul>
<h2><a class="anchor" id="creating_textures"></a>
Creating Textures </h2>
<p>NAP offers a small set of classes to work with textures.</p>
<div class="image">
<img src="../../content/nap_textures.png" alt="nap_textures.png"/>
</div>
<p>The base class for all textures in NAP is <a class="el" href="../../d6/d0e/classnap_1_1_texture2_d.html">Texture2D</a>. This object only holds the GPU data. External CPU storage is required when:</p><ul>
<li>Pixel data needs to be uploaded to the GPU.</li>
<li>Pixel data needs to be read from the GPU to a CPU buffer.</li>
</ul>
<p>CPU storage is provided in the form of a <a class="el" href="../../df/dfc/classnap_1_1_bitmap.html">Bitmap</a>. The bitmap offers a high level CPU interface to work with pixel data. It allows you to:</p><ul>
<li>Retrieve individual pixels from the underlying data buffer.</li>
<li>Set individual pixels in the buffer.</li>
<li>Perform pixel color conversion operations.</li>
<li>Retrieve information such as the amount of color channels, ordering of the pixel data etc.</li>
</ul>
<p>You can also use a more low-level interface to upload data directly into your texture. This interface works with pointers and can be used to stream in large quantities of external data.</p>
<h3><a class="anchor" id="gpu_textures"></a>
GPU Textures</h3>
<p>The <a class="el" href="../../d6/d5e/classnap_1_1_render_texture2_d.html">RenderTexture</a> can be used to declare a texture on the GPU in JSON. Every GPU texture can be attached to a <a class="el" href="../../de/dd1/classnap_1_1_render_target.html">render target</a>. The render target is used by the render service to draw a set of objects directly into the attached texture. This type of texture exposes a set of attributes that can be changed / authored in JSON. The following example creates a color texture on the GPU and attaches it to a render target:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot; : &quot;nap::RenderTexture2D&quot;,</div><div class="line">    &quot;mID&quot; : &quot;ColorTexture&quot;,</div><div class="line">    &quot;Usage&quot;: &quot;Static&quot;,</div><div class="line">    &quot;Width&quot; : 1920,</div><div class="line">    &quot;Height&quot; : 1080,</div><div class="line">    &quot;Format&quot; : &quot;RGBA8&quot;</div><div class="line">},</div><div class="line">{</div><div class="line">    &quot;Type&quot;: &quot;nap::RenderTarget&quot;,</div><div class="line">    &quot;mID&quot;: &quot;RenderTarget&quot;,</div><div class="line">    &quot;mColorTexture&quot;: &quot;ColorTexture&quot;,</div><div class="line">    &quot;mClearColor&quot;: </div><div class="line">    {</div><div class="line">        &quot;x&quot;: 1.0,</div><div class="line">        &quot;y&quot;: 0.0,</div><div class="line">        &quot;z&quot;: 0.0,</div><div class="line">        &quot;w&quot;: 1.0</div><div class="line">    }</div><div class="line">},</div></div><!-- fragment --><p>Note that the <code>Usage</code> of the texture is set to <code>Static</code>. This is important because we never read or write from or to the texture using the CPU. Only the GPU uses the texture as a target for the render operation.</p>
<h3><a class="anchor" id="images"></a>
Images</h3>
<p>An <a class="el" href="../../dd/d82/classnap_1_1_image.html">Image</a> is a two-dimensional texture that manages the data associated with a texture on the CPU and GPU. The CPU data is stored internally as a <a class="el" href="../../df/dfc/classnap_1_1_bitmap.html">bitmap</a>. This makes it easy to:</p><ul>
<li>Quicky upload pixel data from the CPU to the GPU</li>
<li>Transfer pixel data from the GPU to the CPU</li>
</ul>
<p>It is easy to change the contents of an image at runtime:</p>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> App::update()</div><div class="line">{   </div><div class="line">    <span class="comment">// Get the CPU image data as a bitmap</span></div><div class="line">    Bitmap&amp; bitmap = mImage.getBitmap();</div><div class="line"></div><div class="line">    <span class="comment">// Adjust the pixel data here....</span></div><div class="line"></div><div class="line">    <span class="comment">// Upload changes to the GPU</span></div><div class="line">    mImage.update();</div><div class="line">}</div></div><!-- fragment --><h3><a class="anchor" id="image_from_file"></a>
Image From File</h3>
<p><a class="el" href="../../d3/d21/classnap_1_1_image_from_file.html">ImageFromFile</a> allows you to load an image from disk. This object offers the exact same functionality as a native image. You can update your content or read data from the GPU using the same interface. To create an image in JSON:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot; : &quot;nap::ImageFromFile&quot;,</div><div class="line">    &quot;mID&quot; : &quot;background&quot;,</div><div class="line">    &quot;ImagePath&quot; : &quot;background.jpg&quot;,</div><div class="line">    &quot;Usage&quot;: &quot;Static&quot;,</div><div class="line">    &quot;GenerateLods&quot;: true</div><div class="line">}</div></div><!-- fragment --><h2><a class="anchor" id="reading_textures"></a>
Reading Textures From The GPU </h2>
<p>Textures contain the output of a GPU rendering step when they are assigned to a render target. You can read back the result from a texture on the GPU to the CPU using the 2D texture or image interface. The following functions allow you to transfer the rendered texture back from the GPU to the CPU:</p>
<ul>
<li><a class="el" href="../../d6/d0e/classnap_1_1_texture2_d.html#a1e63145d58a31f34a10341b25ead19d5">nap::Texture2D::asyncGetData(Bitmap&amp; bitmap)</a>;</li>
<li><a class="el" href="../../dd/d82/classnap_1_1_image.html#a5783a3145cf47d538f393a5f708fa408">nap::Image::asyncGetData()</a>;</li>
</ul>
<p>You can see that the 2D texture interface requires you to pass in external storage in the form of a bitmap. The image interface will transfer the image back into its internal bitmap. The asyncGetData() function will not stall the CPU and queues the copy operation on the GPU. After the copy is executed by the GPU the data is automatically transferred.</p>
<h2><a class="anchor" id="texture_usage"></a>
Texture Usage </h2>
<p>The texture <code>Usage</code> flag allows you to specify how the texture is going to be used.</p>
<ul>
<li>Static: The texture does not change after initial upload.</li>
<li>DynamicRead: Texture is frequently read from GPU to CPU.</li>
<li>DynamicWrite: Texture is frequently updated from CPU to GPU.</li>
</ul>
<p>It's important to choose the right setting based on your needs. It is for example not allowed to update <code>Static</code> or <code>DynamicRead</code> textures after the initial upload from the CPU because the staging buffer is deleted after upload. Doing so will result in render artifacts (depending on the driver) or potentially a system crash. On the other hand: <code>DynamicWrite</code> allocates additional resources on the GPU and should therefore only be used if you are going to write to the texture more than once from the CPU. Note that it is perfectly safe to set the usage to <code>Static</code> when frequently writing to it on the GPU only, for example when using it as a render target.</p>
<h2><a class="anchor" id="texture_sampling"></a>
Texture Sampling </h2>
<p>A sampler <a class="el" href="../../d4/def/classnap_1_1_sampler.html">parameters</a> controls how a texture is sampled. These are the parameters that can be specified:</p><ul>
<li><code>MinFilter</code>: Controls how the texels are blended when the texture is minified.</li>
<li><code>MaxFilter</code>: Controls how the texels are blended when the texture is magnified.</li>
<li><code>MipMapMode</code>: Controls how texels are blended between mip-maps.</li>
<li><code>AddressModeVertical</code>: How the UV mapping is interpreted vertically.</li>
<li><code>AddressModeHorizontal</code>: How the UV mapping is interpreted horizontally.</li>
<li><code>AnisotropicSamples</code>: Max number of anisotropic filter samples.</li>
<li><code>MaxLodLevel</code>: Max number of lods to use.</li>
</ul>
<p>A LOD level of 0 prevents the texture from mipmapping, ie: the renderer only chooses the highest (native) texture resolution. This setting has no influence when mip mapping is turned off. You can change the parameters of every 2D texture (image, render texture etc.) in JSON:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Samplers&quot;: </div><div class="line">    [</div><div class="line">        {</div><div class="line">            &quot;Type&quot;: &quot;nap::Sampler2D&quot;,</div><div class="line">            &quot;mID&quot;: &quot;tex_input_uniform&quot;,</div><div class="line">            &quot;Name&quot;: &quot;inTexture&quot;,</div><div class="line">            &quot;MinFilter&quot;: &quot;Linear&quot;,</div><div class="line">            &quot;MaxFilter&quot;: &quot;Linear&quot;,</div><div class="line">            &quot;MipMapMode&quot;: &quot;Linear&quot;,</div><div class="line">            &quot;AddressModeVertical&quot;: &quot;ClampToEdge&quot;,</div><div class="line">            &quot;AddressModeHorizontal&quot;: &quot;ClampToEdge&quot;,</div><div class="line">            &quot;AnisotropicSamples&quot;: &quot;Default&quot;,</div><div class="line">            &quot;MaxLodLevel&quot;: 1000,</div><div class="line">            &quot;Texture&quot;: &quot;WorldTexture&quot;</div><div class="line">        }</div><div class="line">    ]</div><div class="line">}</div></div><!-- fragment --><h1><a class="anchor" id="multi_screen"></a>
Windows </h1>
<p>You can add as many windows to your application as you want. Take a look at the multi window demo for a working example. That demo spawns three windows and renders the same set of objects (in different configurations) to every one of them. In your application you have to activate the window you want to render to before issuing any draw commands. This is demonstrated in the example below:</p>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> MultiWindowApp::render()</div><div class="line">{</div><div class="line">    <span class="comment">// Signal the beginning of a new frame, allowing it to be recorded.</span></div><div class="line">    mRenderService-&gt;beginFrame();</div><div class="line"></div><div class="line">    <span class="comment">// Render to window one</span></div><div class="line">    <span class="keywordflow">if</span>(mRenderService-&gt;beginRecording(*mRenderWindowOne))</div><div class="line">    {</div><div class="line">        <span class="comment">// Begin the render pass</span></div><div class="line">        mRenderWindowOne-&gt;beginRendering();</div><div class="line"></div><div class="line">        ...</div><div class="line"></div><div class="line">        <span class="comment">// Draw gui to window one</span></div><div class="line">        mGuiService-&gt;draw();</div><div class="line"></div><div class="line">        <span class="comment">// End rendering and recording</span></div><div class="line">        mRenderWindowOne-&gt;endRendering();</div><div class="line">        mRenderService-&gt;endRecording();</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="comment">// Render to window two</span></div><div class="line">    <span class="keywordflow">if</span>(mRenderService-&gt;beginRecording(*mRenderWindowTwo))</div><div class="line">    {</div><div class="line">        <span class="comment">// Begin render pass</span></div><div class="line">        mRenderWindowTwo-&gt;beginRendering();</div><div class="line"></div><div class="line">        ...</div><div class="line"></div><div class="line">        <span class="comment">// Draw gui to window two</span></div><div class="line">        mGuiService-&gt;draw();</div><div class="line"></div><div class="line">        <span class="comment">// End rendering and recording</span></div><div class="line">        mRenderWindowTwo-&gt;endRendering();</div><div class="line">        mRenderService-&gt;endRecording();</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="comment">// End frame</span></div><div class="line">    mRenderService-&gt;endFrame();</div><div class="line">}</div></div><!-- fragment --><h1><a class="anchor" id="offscreen_rendering"></a>
Offscreen Rendering </h1>
<p>Often you want to render a selection of objects to a texture instead of a screen. But you can't render to a texture directly, you need a <a class="el" href="../../de/dd1/classnap_1_1_render_target.html">render target</a> to do that for you. Every render target requires a link to a color texture. The result of the render step is stored in the texture. You can declare a render target in JSON just like any other resource:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot;: &quot;nap::RenderTexture2D&quot;,</div><div class="line">    &quot;mID&quot;: &quot;OutputColorTexture&quot;,</div><div class="line">    &quot;Usage&quot;: &quot;Static&quot;,</div><div class="line">    &quot;Width&quot;: 1920,</div><div class="line">    &quot;Height&quot;: 1080,</div><div class="line">    &quot;Format&quot;: &quot;RGBA8&quot;</div><div class="line">},</div><div class="line">{</div><div class="line">    &quot;Type&quot;: &quot;nap::RenderTarget&quot;,</div><div class="line">    &quot;mID&quot;: &quot;VideoRenderTarget&quot;,</div><div class="line">    &quot;SampleShading&quot;: true,</div><div class="line">    &quot;Samples&quot;: &quot;Four&quot;,</div><div class="line">    &quot;ClearColor&quot;: </div><div class="line">    {</div><div class="line">        &quot;x&quot;: 1.0,</div><div class="line">        &quot;y&quot;: 0.0,</div><div class="line">        &quot;z&quot;: 0.0,</div><div class="line">        &quot;w&quot;: 1.0</div><div class="line">    },</div><div class="line">    &quot;ColorTexture&quot;: &quot;OutputColorTexture&quot;</div><div class="line">}</div></div><!-- fragment --><p>In this example we create a color texture and a render target. The render target links to the color texture. The only thing left to do is locate the target in your application and give it to the render service together with a selection of components to render. All headless (non window) render operations need to be executed within a beginHeadlessRecording() and endHeadlessRecording() block:</p>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> VideoModulationApp::render()</div><div class="line">{</div><div class="line">    <span class="comment">// Signal the beginning of a new frame, allowing it to be recorded.</span></div><div class="line">    mRenderService-&gt;beginFrame();</div><div class="line"></div><div class="line">    <span class="comment">// Start recording into the headless recording buffer.</span></div><div class="line">    <span class="keywordflow">if</span> (mRenderService-&gt;beginHeadlessRecording())</div><div class="line">    {</div><div class="line">        <span class="comment">// Render into the render target</span></div><div class="line">        mVideoRenderTarget-&gt;beginRendering();</div><div class="line">        ...</div><div class="line">        mVideoRenderTarget-&gt;endRendering();</div><div class="line"></div><div class="line">        <span class="comment">// Tell the render service we are done rendering into render-targets.</span></div><div class="line">        mRenderService-&gt;endHeadlessRecording(); </div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="comment">// Done rendering this frame</span></div><div class="line">    mRenderService-&gt;endFrame();</div><div class="line">}</div></div><!-- fragment --><p>Alternatively you can use the <a class="el" href="../../dc/d0b/classnap_1_1_render_to_texture_component.html">RenderToTextureComponent</a>. This component allows you to render to a texture directly in screen space, without the need to define a render target or mesh, and can be used to apply a 'post process' render step. The video modulation demo uses this component to convert the output of a video player into a greyscale texture.</p>
<h1><a class="anchor" id="cameras"></a>
Cameras </h1>
<p>NAP supports two camera types:</p>
<ul>
<li><a class="el" href="../../de/dac/classnap_1_1_ortho_camera_component.html">Orthographic</a></li>
<li><a class="el" href="../../d6/d3d/classnap_1_1_persp_camera_component.html">PerSpective</a></li>
</ul>
<p>With an orthographic camera the scene is rendered using a flat projection matrix. With an orthographic camera the scene is rendered using a perspective matrix. The render service expects a reference to one of the cameras when rendering a set of objects to a target. You can create as many cameras as you want by adding one as a component to an entity in JSON:</p>
<div class="fragment"><div class="line">{</div><div class="line">    &quot;Type&quot; : &quot;nap::Entity&quot;,</div><div class="line">    &quot;mID&quot;: &quot;Camera&quot;,</div><div class="line">    &quot;Components&quot; : </div><div class="line">    [</div><div class="line">        {</div><div class="line">            &quot;Type&quot; : &quot;nap::PerspCameraComponent&quot;,</div><div class="line">            &quot;Properties&quot;: </div><div class="line">            {</div><div class="line">                &quot;FieldOfView&quot;: 45.0,</div><div class="line">                &quot;NearClippingPlane&quot; : 1,</div><div class="line">                &quot;FarClippingPlane&quot; : 1000.0</div><div class="line">            }</div><div class="line">        },</div><div class="line">        {</div><div class="line">            &quot;Type&quot; : &quot;nap::TransformComponent&quot;</div><div class="line">        }</div><div class="line">    ]</div><div class="line">}</div></div><!-- fragment --><p>Two things define a camera: its location in the world and type. The world space location of a camera is used to compose the view matrix. The camera projection method is used to compose the projection matrix. Both are extracted by the renderer and forwarded to the shader. Every camera therefore needs access to a transform component that is a sibling of the parent entity. For a working example take a look at the multi window demo. This demo renders a set of objects to different windows using a mix of cameras. </p>
</div></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.13-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
<a href="http://www.doxygen.org/index.html"> Generated by doxygen</a></small></address>
</body>
</html>
